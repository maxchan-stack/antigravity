import httpx
from bs4 import BeautifulSoup
from datetime import datetime, timezone
from typing import List
from .base import BaseCrawler
from ..models import Article
from loguru import logger

class GithubCrawler(BaseCrawler):
    """GitHub Trending çˆ¬èŸ²"""
    
    BASE_URL = "https://github.com/trending"

    async def fetch(self) -> List[Article]:
        language = self.config.params.get("language", "")
        url = f"{self.BASE_URL}/{language}" if language else self.BASE_URL
        
        logger.debug(f"ğŸ” è«‹æ±‚ GitHub Trending: {url}")

        async with httpx.AsyncClient(timeout=30.0) as client:
            try:
                response = await client.get(url, headers={"User-Agent": "Mozilla/5.0"})
                if response.status_code != 200:
                    logger.error(f"âŒ GitHub å›å‚³éŒ¯èª¤: {response.status_code}")
                    return []
                
                soup = BeautifulSoup(response.text, "html.parser")
                repo_list = soup.select("article.Box-row")
                logger.debug(f"âœ… æˆåŠŸè§£æ Trending, å…±æœ‰ {len(repo_list)} æ¢é …ç›®")
                
                articles = []
                for repo in repo_list:
                    try:
                        title_tag = repo.select_one("h2 a")
                        title = title_tag.get_text(strip=True).replace(" / ", "/")
                        link = "https://github.com" + title_tag["href"]
                        
                        desc_tag = repo.select_one("p")
                        desc = desc_tag.get_text(strip=True) if desc_tag else "ç„¡æè¿°"
                        
                        # æŠ“å–æ˜Ÿæ•¸ (ç°¡åŒ–ï¼Œä½œç‚ºæ–°é®®åº¦/æ¬Šå¨æ€§åƒè€ƒ)
                        star_tag = repo.select_one("a[href$='/stargazers']")
                        stars = star_tag.get_text(strip=True) if star_tag else "0"
                        
                        article = Article(
                            id=f"github-{title}",
                            title=title,
                            authors=["GitHub Community"], # Trending å°ˆæ¡ˆé€šå¸¸ç‚ºåœ˜éšŠæˆ–ç¤¾å€
                            summary=f"GitHub ç†±é–€å°ˆæ¡ˆ: {desc} (Stars: {stars})",
                            url=link,
                            source="github",
                            published_date=datetime.now(timezone.utc) # Trending ä»£è¡¨ç•¶ä¸‹ç†±é–€
                        )
                        articles.append(article)
                    except Exception as e:
                        logger.warning(f"âš ï¸ è§£æ GitHub é …ç›®å¤±æ•—: {e}")
                        continue
                        
                return articles
            except Exception as e:
                logger.error(f"âŒ æ“·å– GitHub è³‡æ–™å¤±æ•—: {e}")
                return []
