import httpx
from datetime import datetime, timezone
from typing import List
from .base import BaseCrawler
from ..models import Article
from loguru import logger

class HackerNewsCrawler(BaseCrawler):
    """Hacker News çˆ¬èŸ²"""
    
    BASE_URL = "https://hacker-news.firebaseio.com/v0"

    async def fetch(self) -> List[Article]:
        max_items = self.config.params.get("max_items", 10)
        
        logger.debug(f"ğŸ” è«‹æ±‚ Hacker News Top Stories (å‰ {max_items} å‰‡)")

        async with httpx.AsyncClient(timeout=30.0) as client:
            try:
                # 1. ç²å–ç†±é–€æ–‡ç«  ID åˆ—è¡¨
                response = await client.get(f"{self.BASE_URL}/topstories.json")
                if response.status_code != 200:
                    logger.error(f"âŒ HN API å›å‚³éŒ¯èª¤: {response.status_code}")
                    return []
                
                story_ids = response.json()[:max_items]
                logger.debug(f"âœ… ç²å¾— {len(story_ids)} å‰‡ç†±é–€æ–‡ç«  ID")
                
                # 2. é€ä¸€ç²å–æ–‡ç« è©³æƒ…
                articles = []
                for story_id in story_ids:
                    try:
                        item_resp = await client.get(f"{self.BASE_URL}/item/{story_id}.json")
                        if item_resp.status_code != 200:
                            continue
                        
                        item = item_resp.json()
                        if not item or item.get("type") != "story":
                            continue
                        
                        # è§£ææ™‚é–“ (Unix timestamp)
                        ts = item.get("time", 0)
                        dt = datetime.fromtimestamp(ts, tz=timezone.utc)
                        
                        article = Article(
                            id=f"hn-{story_id}",
                            title=self.clean_text(item.get("title", "")),
                            authors=[item.get("by", "Unknown")],
                            summary=f"HN ç†±é–€è©±é¡Œ (Score: {item.get('score', 0)}, Comments: {item.get('descendants', 0)})",
                            url=item.get("url", f"https://news.ycombinator.com/item?id={story_id}"),
                            source="hn",
                            published_date=dt
                        )
                        articles.append(article)
                    except Exception as e:
                        logger.warning(f"âš ï¸ è§£æ HN é …ç›® {story_id} å¤±æ•—: {e}")
                        continue
                
                logger.debug(f"âœ… æˆåŠŸè§£æ {len(articles)} å‰‡ HN æ–‡ç« ")
                return articles
            except Exception as e:
                logger.error(f"âŒ æ“·å– HN è³‡æ–™å¤±æ•—: {e}")
                return []
