#!/usr/bin/env python3
"""
Market Intel AI - æ’ç¨‹è…³æœ¬
==========================
è² è²¬å”èª¿ï¼š
1. FinancialCrawler (æŠ“å– Google Finance RSS)
2. MarketSentimentAnalyzer (Gemini æƒ…ç·’åˆ†æ)
3. DatabaseManager (å„²å­˜)
"""

import asyncio
import argparse
from datetime import datetime
from loguru import logger
import os
from dotenv import load_dotenv

# ç¢ºä¿è¼‰å…¥ .env
load_dotenv()

from src.crawler.finance_crawler import FinancialCrawler
from src.analyzer.sentiment_engine import MarketSentimentAnalyzer
from src.database.storage import DatabaseManager
from src.models import SourceConfig
from src.config import config

async def run_pipeline():
    """åŸ·è¡Œè²¡ç¶“æ–°èåˆ†ææµç¨‹"""
    start_time = datetime.now()
    logger.info(f"ğŸš€ [Market Intel] é–‹å§‹åŸ·è¡Œå¸‚å ´æƒ…å ±åˆ†æ...")
    
    # 1. æŠ“å–
    crawler = FinancialCrawler(SourceConfig(
        name="finance", 
        params={"tickers": config.stock_tickers}
    ))
    
    raw_articles = await crawler.fetch()
    if not raw_articles:
        logger.info("âš ï¸ ç„¡æ–°æ–°è")
        return

    # 2. éæ¿¾å·²å­˜åœ¨çš„
    db = DatabaseManager()
    processed_ids = db.get_processed_ids()
    new_articles = [a for a in raw_articles if a.id not in processed_ids]
    
    logger.info(f"ğŸ“¥ æŠ“å– {len(raw_articles)} -> æ–°å¢ {len(new_articles)}")
    
    if not new_articles:
        return

    # 3. AI æƒ…ç·’åˆ†æ
    analyzer = MarketSentimentAnalyzer()
    analyzed_articles = await analyzer.batch_analyze(new_articles)
    
    # 4. å­˜æª”
    db.save_articles(analyzed_articles)
    
    elapsed = (datetime.now() - start_time).total_seconds()
    logger.success(f"ğŸ‰ æµç¨‹å®Œæˆï¼åˆ†æäº† {len(analyzed_articles)} ç¯‡è²¡ç¶“æ–°èï¼Œè€—æ™‚ {elapsed:.1f}s")


if __name__ == "__main__":
    asyncio.run(run_pipeline())
