import json
from typing import List
from ..models import Article
from .llm import LLMClient
from loguru import logger

class MarketSentimentAnalyzer:
    """å¸‚å ´æƒ…ç·’åˆ†æå¼•æ“ (AI Analyst)"""
    
    def __init__(self):
        self.llm = LLMClient()

    async def analyze(self, article: Article) -> Article:
        """ä½¿ç”¨ AI åˆ†ææ–°èå°è‚¡åƒ¹çš„å½±éŸ¿"""
        logger.info(f"ğŸ¤– æ­£åœ¨åˆ†æå¸‚å ´æƒ…ç·’: {article.title}")
        
        system_prompt = """ä½ æ˜¯ä¸€ä½è¯çˆ¾è¡—è³‡æ·±åˆ†æå¸«ï¼Œæ“…é•·è§£è®€æ–°èå°è‚¡åƒ¹çš„å½±éŸ¿ã€‚
è«‹æ ¹æ“šæ–°èå…§å®¹é€²è¡Œå°ˆæ¥­è©•ä¼°ã€‚"""
        
        user_prompt = f"""è«‹åˆ†æä»¥ä¸‹è²¡ç¶“æ–°èå°è©²å…¬å¸å·²åŠå¸‚å ´çš„æ½›åœ¨å½±éŸ¿ï¼š

---
æ¨™é¡Œ: {article.title}
æ‘˜è¦: {article.summary}
---

è«‹å›å‚³ JSON æ ¼å¼ï¼ŒåŒ…å«ä»¥ä¸‹æ¬„ä½ï¼š
1. sentiment: "bullish" (çœ‹å¤š), "bearish" (çœ‹ç©º), æˆ– "neutral" (ä¸­æ€§)
2. market_impact_score: 0-100 (åˆ†æ•¸è¶Šé«˜ä»£è¡¨å°è‚¡åƒ¹æ³¢å‹•å½±éŸ¿è¶Šå¤§)
3. ai_summary: ä¸€å¥è©±ç¹é«”ä¸­æ–‡çŸ­è©• (ä¾‹å¦‚ï¼šè²¡å ±å„ªæ–¼é æœŸï¼Œä½†æŒ‡å¼•ç–²å¼±)
4. key_risks: åˆ—å‡º 1-3 å€‹æ½›åœ¨é¢¨éšªé» (List[str])
5. tags: 3-5 å€‹ç›¸é—œé—œéµå­— (ä¾‹å¦‚ï¼šEarnings, AI, Chip War)

è¼¸å‡ºç¯„ä¾‹ï¼š
{{
  "sentiment": "bullish",
  "market_impact_score": 85,
  "ai_summary": "...",
  "key_risks": ["..."],
  "tags": ["..."]
}}
"""
        
        response = await self.llm.chat_completion(system_prompt, user_prompt)
        
        if response:
            try:
                # æ¸…ç† Markdown ä»£ç¢¼å€å¡Š
                clean_json = response.strip()
                if clean_json.startswith("```json"):
                    clean_json = clean_json[7:-3].strip()
                elif clean_json.startswith("```"):
                    clean_json = clean_json[3:-3].strip()
                
                data = json.loads(clean_json)
                
                # æ›´æ–°æ–‡ç« æ¬„ä½
                article.sentiment = data.get("sentiment", "neutral")
                article.market_impact_score = data.get("market_impact_score", 0)
                article.ai_summary = data.get("ai_summary", article.summary)
                article.key_risks = data.get("key_risks", [])
                article.tags = data.get("tags", article.tags)
                
                # åŒæ­¥æ›´æ–° Trust Score ä»¥åæ˜ é‡è¦æ€§
                article.trust_score = float(article.market_impact_score)
                
                logger.success(f"âœ… åˆ†æå®Œæˆ [{article.sentiment.upper()}]: {article.title}")
                
            except Exception as e:
                logger.error(f"âŒ è§£æ AI å›æ‡‰å¤±æ•—: {e} | åŸå§‹å›æ‡‰: {response}")
        
        return article

    async def batch_analyze(self, articles: List[Article]) -> List[Article]:
        """æ‰¹é‡åˆ†æ"""
        results = []
        for art in articles:
            analyzed = await self.analyze(art)
            results.append(analyzed)
        return results
